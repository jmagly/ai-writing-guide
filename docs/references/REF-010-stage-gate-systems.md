# REF-010: Stage-Gate Systems - A New Tool for Managing New Products

## Citation

Cooper, R. G. (1990). Stage-gate systems: A new tool for managing new products. *Business Horizons*, 33(3), 44-54.

**DOI**: Not available (pre-digital era publication)
**Link**: [ResearchGate](https://www.researchgate.net/publication/4883499_Stage-Gate_Systems_A_New_Tool_for_Managing_New_Products)

## Document Profile

| Attribute | Value |
|-----------|-------|
| **Publication Type** | Journal Article |
| **Venue** | Business Horizons (peer-reviewed) |
| **Year** | 1990 |
| **Field** | Product Development, Project Management |
| **Methodology** | Empirical Research (203 projects), Process Framework |
| **Evidence Level** | High (quantitative study + practitioner validation) |
| **Citation Impact** | High (foundational Stage-Gate methodology) |
| **Industry Adoption** | Very High (widely adopted in manufacturing, software) |

## Executive Summary

Robert Cooper introduced the Stage-Gate system, a disciplined framework for managing new product development from idea to launch. The methodology divides the innovation process into discrete **stages** (work phases) separated by **gates** (quality checkpoints). At each gate, cross-functional teams evaluate deliverables against explicit criteria and make go/kill/hold/recycle decisions.

Cooper's research on 203 new product projects revealed that quality of execution—not just having a process—distinguishes winners from losers. Successful products spent 3x more on preliminary market assessment and 6x more on launch activities compared to failures. The Stage-Gate framework enforces this quality through mandatory deliverables and multi-perspective reviews at each gate.

**AIWG Relevance**: AIWG's SDLC workflow (Inception → Elaboration → Construction → Transition) is a direct implementation of Stage-Gate. Phase gates (LO, LA, IOC, PR) enforce quality criteria before progression. Multi-agent gate reviews (Architecture Designer, Security Auditor, Test Engineer) parallel Cooper's cross-functional gatekeeper teams.

## Key Findings

### 1. The Stage-Gate Framework: Stages and Gates

Cooper defines the core architecture:

- **Stages**: Work phases with defined activities, cross-functional teams, and integration points
- **Gates**: Quality control checkpoints where deliverables are evaluated against criteria
- **Gatekeepers**: Cross-functional group of decision makers (typically senior managers)
- **Deliverables**: Required outputs from each stage (market analysis, technical assessment, business case)

The typical 5-stage model:
1. **Stage 1 - Preliminary Investigation**: Quick, inexpensive scoping
2. **Stage 2 - Detailed Investigation**: Build business case (market, technical, financial)
3. **Stage 3 - Development**: Design, develop, test product
4. **Stage 4 - Testing and Validation**: In-house, field, market tests
5. **Stage 5 - Full Production and Launch**: Commercialization

Each stage is followed by a gate (screening, second screen, go to development, go to testing, go to launch).

### 2. Quality of Execution Distinguishes Winners from Losers

Cooper's research study of 203 new product projects revealed:

- **63% of managers** felt their success rate was "disappointing"
- Successful products spent **3x more on preliminary market assessment** (Stage 1)
- **6x more money on launch activities** (Stage 5) compared to failures
- The largest quality gap: detailed market studies (Stage 2)

**Key finding** (p. 47): "The number one success factor is quality of execution of key activities—doing the activities and doing them well."

| Activity | Success Score | Failure Score | Gap |
|----------|--------------|---------------|-----|
| Preliminary Market Assessment | ~6.8 | ~3.5 | **Large** |
| Detailed Market Study | ~6.5 | ~3.0 | **Largest** |
| Preliminary Technical Assessment | ~6.2 | ~4.0 | Medium |
| Market Launch | ~7.0 | ~4.5 | Large |

(Scores from Figure 2, p. 47, on 0-10 scale where 10 = excellent execution)

### 3. Gates Provide Quality Control and Go/Kill Decisions

Gates enforce discipline through:

1. **Defined Deliverables**: What must be presented (market analysis, prototype, test results)
2. **Explicit Criteria**: Both mandatory (must-meet) and desirable (should-meet)
3. **Decision Options**: GO, KILL, HOLD, RECYCLE (return to previous stage)
4. **Resource Allocation**: Next stage receives funding only after gate approval

Cooper emphasizes: "The gates serve as quality-control checkpoints, go/kill decision points, and prioritization points" (p. 48).

**Gate Criteria Examples** (p. 49):
- Strategic fit with business objectives
- Market attractiveness (size, growth, competitive intensity)
- Technical feasibility
- Financial return (NPV, IRR, payback period)
- Resource availability

### 4. Parallel Processing Within Stages

Unlike traditional serial waterfall, Stage-Gate allows **concurrent activities within stages** (p. 49):

- Market studies and technical assessments run simultaneously in Stage 2
- Development and test planning overlap in Stage 3
- Production ramp-up begins during Stage 4 testing

This "third-generation" approach reduces time-to-market while maintaining gate discipline. Cooper notes: "Stage-Gate is not a functional, sequential process. Activities within stages are undertaken concurrently and by people from different functional areas working together as a team" (p. 50).

### 5. Cross-Functional Teams and Multi-Perspective Evaluation

Each stage involves cross-functional teams (marketing, engineering, manufacturing, finance). Gates require **multi-perspective approval**:

- **Marketing**: Customer need validation, competitive positioning
- **Engineering**: Technical feasibility, manufacturability
- **Finance**: ROI, resource requirements
- **Operations**: Production capability, supply chain

Cooper's principle: "A single functional perspective is not enough. Gates demand an integrated, holistic view" (p. 49).

## Benchmark/Experimental Results

### Study Design

- **Sample**: 203 new product projects from multiple industries
- **Method**: Comparative analysis of successful vs. failed products
- **Metrics**: Execution quality scores (0-10 scale), resource allocation, success rates

### Key Quantitative Findings

| Metric | Successful Products | Failed Products | Ratio |
|--------|-------------------|----------------|-------|
| **Preliminary Market Assessment Spending** | 3x baseline | 1x baseline | **3:1** |
| **Market Launch Spending** | 6x baseline | 1x baseline | **6:1** |
| **Detailed Market Study Quality** | 6.5/10 | 3.0/10 | 2.2:1 |
| **Preliminary Technical Assessment Quality** | 6.2/10 | 4.0/10 | 1.6:1 |
| **Up-front Homework Quality** | High | Low | Distinguishing factor |

### Success Factor Rankings (p. 45)

Cooper's research identified top success factors:

1. **Quality of Execution** - Doing activities and doing them well
2. **Product Advantage** - Differentiation, superior value
3. **Market Knowledge** - Understanding customer needs deeply
4. **Pre-Development Homework** - Solid upfront investigation before development
5. **Sharp Early Product Definition** - Clear requirements before Stage 3

The Stage-Gate system specifically addresses factors #1, #4, and #5 through enforced gate criteria.

### Time-to-Market Impact

Stage-Gate implementations showed (p. 50):
- **30-50% reduction in development cycle time** through parallel processing
- **Fewer late-stage changes** due to solid upfront work
- **Higher first-time success rates** from multi-perspective gate reviews

## Key Quotes

> "A Stage-Gate system is both a conceptual and an operational model for moving a new product from idea to launch. It is a blueprint for managing the new product development process to improve effectiveness and efficiency." (p. 45)

> "Quality of execution is the number one success factor in new product development. The most important driver of success and profitability is doing the activities and doing them well." (p. 47)

> "The gates serve as quality-control checkpoints, go/kill decision points, and prioritization points. They are the scrums on the playing field where the team converges, gets together, and makes important decisions." (p. 48)

> "Each gate consists of: 1) deliverables (what the project leader and team must bring to the decision point), 2) criteria (questions or metrics on which the project is judged), and 3) outputs (a decision: go/kill/hold/recycle)." (p. 48-49)

> "Stage-Gate is not a functional, sequential process. Activities within stages are undertaken concurrently and by people from different functional areas working together as a team." (p. 50)

> "The gates provide the teeth that make the process work. Too many managers pay lip service to the idea of a disciplined new product process, but fail to provide the discipline. Gates are where the discipline happens." (p. 49)

> "One of the most important principles is this: The quality of execution at Stage 1—the preliminary investigation—is often as important as the quality of execution at Stage 3, the Development stage." (p. 47)

## AIWG Implementation Mapping

### Direct Implementation: SDLC Phase Gates

AIWG's Software Development Lifecycle is a **direct Stage-Gate implementation**:

| Cooper Stage-Gate | AIWG SDLC Phase | Gate Checkpoint | Key Deliverables |
|-------------------|-----------------|-----------------|------------------|
| **Stage 0: Discovery** | Intake | n/a | Intake Form, Solution Profile |
| **Gate 1: Initial Screen** | → | **Lifecycle Objective (LO)** | Feasibility confirmed |
| **Stage 1: Scoping** | Inception | Vision, preliminary scope | Vision Doc, Use Cases, Risk Register |
| **Gate 2: Second Screen** | → | **Lifecycle Architecture (LA)** | Architecture baselined |
| **Stage 2: Build Business Case** | Elaboration | Architecture, feasibility | SAD, ADRs, Test Strategy, NFRs |
| **Gate 3: Go to Development** | → | **Initial Operational Capability (IOC)** | System ready for release |
| **Stage 3: Development** | Construction | Implementation, testing | Code, Unit Tests, Integration Tests |
| **Gate 4: Go to Testing** | → | **Product Release (PR)** | Production-ready |
| **Stage 4: Testing/Validation** | Transition | Deployment, validation | Deployment Plan, Monitoring |
| **Gate 5: Go to Launch** | → | **Production Handoff** | Operational |
| **Stage 5: Launch** | Production | Operations, support | Runbooks, Incident Response |

### Gate Criteria Implementation

AIWG implements Cooper's gate criteria structure in `.aiwg/planning/gate-checklists/`:

**Example: Lifecycle Architecture (LA) Gate**

```markdown
# Gate: Elaboration → Construction (LA Gate)

## Mandatory Criteria (Must-Meet)
- [ ] Software Architecture Document (SAD) baselined
- [ ] 3-5 Architecture Decision Records (ADRs) approved
- [ ] Master Test Plan defined with coverage targets
- [ ] Risk register updated with mitigation strategies
- [ ] NFR modules completed (Security, Performance, Reliability)

## Desirable Criteria (Should-Meet)
- [ ] Prototype or proof-of-concept validated
- [ ] Key technical risks retired
- [ ] Development environment configured
- [ ] CI/CD pipeline outlined

## Gatekeepers (Multi-Agent Review)
- **Architecture Designer**: Technical soundness, scalability
- **Security Auditor**: Security requirements, threat model
- **Test Engineer**: Testability, coverage strategy
- **Project Manager**: Schedule feasibility, resource allocation
- **Product Owner**: Business value alignment

## Decision Options
- **GO**: All mandatory criteria met, proceed to Construction
- **HOLD**: Minor gaps, 1-2 week remediation, re-gate
- **RECYCLE**: Significant issues, return to Elaboration with feedback
- **KILL**: Project not viable (technical, business, or resource constraints)
```

This directly maps to Cooper's gate structure (p. 48-49): deliverables, criteria, and outputs.

### Parallel Processing Within Phases

AIWG implements Cooper's "third-generation" parallel processing (p. 50):

**Elaboration Phase - Concurrent Activities**:
- Architecture design (Architecture Designer)
- Security threat modeling (Security Auditor)
- Test strategy development (Test Engineer)
- NFR definition (Requirements Analyst)
- Risk identification (Risk Manager)

**Construction Phase - Concurrent Activities**:
- Feature development (multiple Feature Developers)
- Unit test creation (Test Engineer)
- Code review (Code Reviewer)
- Security scanning (Security Auditor)
- Documentation (Technical Writer)

This parallelism reduces time-to-market while maintaining gate discipline.

### Cross-Functional Gatekeepers = Multi-Agent Reviews

Cooper's cross-functional gatekeeper teams (p. 49) map directly to AIWG's multi-agent gate reviews:

| Business Function | AIWG Agent | Gate Responsibility |
|------------------|------------|---------------------|
| **Product Management** | Product Owner | Business value, user needs |
| **Engineering** | Architecture Designer | Technical feasibility |
| **Quality** | Test Engineer | Testability, quality assurance |
| **Security** | Security Auditor | Security requirements |
| **Operations** | DevOps Engineer | Deployability, operability |
| **Project Management** | Project Manager | Schedule, resources |

Each gate requires **unanimous approval** from relevant agents—no single functional perspective can override concerns.

### Quality of Execution Enforcement

Cooper's #1 success factor—quality of execution (p. 47)—is enforced through:

1. **Template-First Approach** (see @REF-006-cognitive-load-theory.md):
   - Every deliverable has a template (SAD, ADR, Test Plan)
   - Reduces cognitive load, ensures completeness

2. **Agent Tools Enforce Quality**:
   - `architecture-designer-agent.md` has tools: `diagram-tool`, `adr-generator`
   - `test-engineer-agent.md` has tools: `coverage-analyzer`, `test-generator`
   - Agents cannot approve gates without using quality tools

3. **Artifact Validation**:
   - Gates check for artifact completeness (all sections filled)
   - Cross-references verified (traceability)
   - Acceptance criteria defined and testable

### Preventing Poor Execution (Cooper's Core Problem)

Cooper found that 63% of managers were disappointed with success rates due to poor execution (p. 47). AIWG addresses this:

| Cooper's Problem | AIWG Solution |
|-----------------|---------------|
| "Skipping steps" | Gates block progression without deliverables |
| "Cursory execution" | Templates + agent tools enforce thoroughness |
| "Single-function perspective" | Multi-agent reviews required |
| "No go/kill discipline" | Explicit gate criteria, decision tracking |
| "Poor upfront homework" | Inception/Elaboration cannot be skipped |

## Cross-References

### Related AIWG Concepts

- **@REF-006-cognitive-load-theory.md**: Template-first approach reduces cognitive load during stages
- **@REF-007-mixture-of-experts.md**: Multi-agent architecture enables cross-functional gate reviews
- **@REF-011-requirements-traceability.md**: Traceability ensures deliverables connect across stages/gates

### AIWG Implementation Files

- **Phase Transition Commands**: `.claude/commands/flow-*-to-*.md` (execute gate checks)
- **Gate Checklists**: `.aiwg/planning/gate-checklists/` (criteria for each gate)
- **SDLC Framework**: `agentic/code/frameworks/sdlc-complete/` (orchestrator logic)
- **Agent Manifests**: `agentic/code/frameworks/sdlc-complete/agents/` (gatekeeper agents)

### Related REF Papers

- **REF-005**: Miller's Law informs gate criteria sizing (5-7 items per checklist)
- **REF-006**: Cognitive Load Theory justifies template-driven stage execution
- **REF-007**: Mixture of Experts provides theoretical basis for multi-agent gatekeepers
- **REF-011**: Requirements Traceability ensures deliverable continuity across stages

## Quick Reference Locations

| Stage-Gate Concept | AIWG Location | Format |
|--------------------|---------------|--------|
| **Stage Definitions** | `agentic/code/frameworks/sdlc-complete/docs/phases/` | Markdown |
| **Gate Checklists** | `.aiwg/planning/gate-checklists/` | Markdown |
| **Gate Transition Commands** | `.claude/commands/flow-*-to-*.md` | Agent Commands |
| **Gatekeeper Agents** | `agentic/code/frameworks/sdlc-complete/agents/` | JSON Manifests |
| **Deliverable Templates** | `agentic/code/frameworks/sdlc-complete/templates/` | Markdown |
| **Gate Status Tracking** | `.aiwg/planning/phase-plan-*.md` | Markdown |
| **Quality Criteria** | `agentic/code/frameworks/sdlc-complete/docs/quality-gates.md` | Markdown |

## Revision History

| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2026-01-24 | 1.0 | Research Acquisition (#74) | Initial reference entry |
| 2026-01-24 | 2.0 | Technical Researcher | Comprehensive research documentation with experimental results, AIWG mapping |
