# Content Validation Checklist

## Pre-Writing Validation

- [ ] Have I read the actual source material (not just searched)?
- [ ] Do I have specific numbers, dates, and names?
- [ ] Am I clear on what actually happened vs. what sounds good?
- [ ] Have I identified what went wrong or was difficult?

## During Writing Validation

### Phrase Check

- [ ] Searched for "seamlessly" → Removed
- [ ] Searched for "Moreover" → Removed
- [ ] Searched for "crucial role" → Replaced
- [ ] Searched for "comprehensive" → Made specific
- [ ] Searched for "innovative" → Used actual technique name
- [ ] Searched for "transform" → Found better verb
- [ ] Searched for "leverage" → Changed to "use"

### Structure Check

- [ ] Paragraph lengths vary (1-5 sentences)
- [ ] Different paragraph openings
- [ ] No formulaic intro → body → conclusion pattern
- [ ] Mixed sentence lengths
- [ ] No summary paragraph at end

### Voice Check

- [ ] Includes at least one opinion
- [ ] Mentions at least one problem/challenge
- [ ] Contains specific technical details
- [ ] Has context for decisions
- [ ] Sounds conversational, not formal

### Specificity Check

- [ ] Vague improvements → Exact metrics
- [ ] General descriptions → Specific technologies
- [ ] Abstract benefits → Concrete outcomes
- [ ] Broad statements → Narrow facts

## Post-Writing Validation

### The Read-Aloud Test
Read the content aloud and check:

- [ ] Does it sound like a real person?
- [ ] Would you say this to a colleague?
- [ ] Any parts sound like Wikipedia?
- [ ] Any parts sound like marketing?

### The Tired Developer Test
Could you imagine:

- [ ] A developer writing this at 5pm?
- [ ] Someone who actually built this writing it?
- [ ] This being said in a stand-up meeting?
- [ ] This appearing in a Slack message?

### The AI Detection Test
Count occurrences:

- [ ] Em-dashes: Maximum 2 per document
- [ ] Three-item lists: Maximum 1
- [ ] "Solution" uses: Try for zero
- [ ] Formal transitions: Should be zero
- [ ] Perfect outcomes: Should have some problems

### The Authenticity Score

Give yourself 1 point for each:

- [ ] Specific metric included
- [ ] Problem or failure mentioned
- [ ] Opinion stated
- [ ] Trade-off explained
- [ ] Context provided
- [ ] Technical detail specified
- [ ] Informal language used
- [ ] Deadline or constraint mentioned
- [ ] Team dynamic referenced
- [ ] Learning or mistake admitted

**Score interpretation:**
- 0-3: Too polished, likely AI-detected
- 4-6: Getting better, needs more authenticity
- 7-10: Sounds human and experienced

## Quick Fixes for Common Issues

### If it sounds too formal

1. Remove "It is worth noting that"
2. Replace "utilize" with "use"
3. Cut sentence length in half
4. Add a contraction
5. Include a fragment

### If it sounds too positive

1. Add what went wrong
2. Mention the trade-off
3. Include the constraint
4. State what you'd do differently
5. Admit the hack or shortcut

### If it sounds too vague

1. Add a specific number
2. Name the technology
3. Give the timeline
4. State the metric
5. Include the version

### If it sounds too helpful

1. Remove "I hope this helps"
2. Cut the explanation of why
3. Just state the fact
4. Skip the context setting
5. Don't summarize

## Final Sign-Off Questions

Before submitting, answer:

1. **Would I send this to my team?** Y/N
2. **Does this sound like me on a normal day?** Y/N
3. **Did I mention anything that went wrong?** Y/N
4. **Are my numbers specific?** Y/N
5. **Did I avoid all banned phrases?** Y/N

If any answer is No, revise.

## Remember

Perfect content is suspicious. Real content has:
- Rough edges
- Strong opinions
- Specific details
- Actual problems
- Human voice

Ship it when it sounds real, not when it sounds perfect.
